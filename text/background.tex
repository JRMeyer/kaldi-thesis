% !TEX root = main.tex
\chapter{Background}
\label{cha:background}

%{{{
% TODO FIND THE BEST INTRODUCTION FROM:
%   Spoken language understanding
%   Discriminative Training and Acoustic Modeling for Speech Recognition
%   Markov Models for Pattern Recognition -Fink
% 
% TODO Watch NLP again on http://coursera.com check it for references for the good explanations
% 
% TODO one goal of the EXPECTED goals of writing thesis 
%       Show that you understand given topic
%       Show that you can write and talk about given topic
%}}}

The statistical methods for continuous speech recognition were established more than 30 years ago. 
The most popular statistical methods are based on \ac{HMM} and n-grams \ac{LM},
which are also used in Kaldi, the toolkit of our choice.

The first Section~\ref{sec:back_asr} introduces speech preprocessing, \ac{AM} and \ac{LM} training
and explains the principle of speech decoding.

Next three sections describe decoding or training models for particular software.
The Kaldi toolkit is described in Section~\ref{sec:back_kaldi}, 
the \ac{HTK} toolkit in Section~\ref{sec:back_htk} and 
the OpenJulius decoder in Section~\ref{sec:back_julius}.

\section{Automatic speech recognition}
\label{sec:back_asr}

% Section~\ref{sec:general_introduction} provides an~introduction into speech recognition with \ac{HMM}. 
% It concisely describes components of speech recognition system. The~algorithms for training acoustic language models 
% as well for decoding are introduced. In~Section~\ref{sec:fst} the~advantages of Finite State Transducers 
% in~speech recognition are discussed.

% \section{Introduction to speech recognition} 
% \label{sec:general_introduction}
% \ml{ASR hypothesis}
% Let us introduce speech recognition. Automatic speech recognition is a process
% that produces an \ac{ASR} hypothesis for given audio input. 
% For simplicity, let us for suppose that ASR hypothesis is the textual transcription of speech in the input audio. 
% In~Subsection~\ref{sub:lattice} we will describe lattices as another output format convenient for dialog systems.

The goal of statistical \ac{ASR} is to decode 
the best speech transcription for given speech recording.
Formally, we search for the most probable sequence of~words $w^*$ given the acoustic observations $a$.
See Equation~\ref{eq:best_seq}, which can be simplified to Equation~\ref{eq:best_fix},
because we want decode $w^*$ for fixed speech $a$.

\begin{equation}\label{eq:best_seq}
    w^* = argmax_{w}\{P(w \mid a)\} = argmax_{w}\{\frac{P(a \mid w) * P(w)}{P(a)}\}
\end{equation}

\begin{equation}\label{eq:best_fix}
    w^* = argmax_{w}\{P(w \mid a)\} = argmax_{w}\{P(a \mid w) * P(w)\}
\end{equation}

The task of acoustic modeling is to estimate the probability $P(a \mid w)$,
which we describe in Section~\ref{sub:am}. 
Similarly, the \ac{LM} represents the probability $P(w)$.
We describe language modeling in Section~\ref{sub:lm}.

Improving the accuracy of speech recognition engine is dependent
mainly on improving the \ac{AM} and also the \ac{LM}.
The \ac{AM} and \ac{LM} are typically trained separately 
and stored on hard disc.

\begin{figure}[!htp]
    \begin{center}
    \input{images/asr-components}
    \caption{Architecture of statistical speech recognizer\cite{ney1990acoustic}}
    \label{fig:components} 
    \end{center}
\end{figure}

Typically it is easier to model preprocessed speech, 
so various feature and model space transforms are applied before \ac{AM} training.
The speech recognizer has to use the same speech preprocessing,
which is used for \ac{AM} model estimation.
See Figure~\ref{fig:components}.


% TODO delete or apply
% In machine learning there are usually distinguished two kinds of learning algorithms, supervised and unsupervised.
% 
% {\it Supervised learning}\/ is the~machine learning task of inferring a function from labeled training data.\cite{mohri2012foundations}. Labeled data is set of training examples pairs. The pairs consists of input features and desired output as captured in~Figure~\ref{fig:supervised}. The supervised learning algorithm infers a function partially influenced by the training examples and partially determined by the algorithm itself. In ideal case, the inferred function would be able to predict correct output values for unseen input data. 
% The inferred function is often called {\it model}. 
% \todo{is it important? 
% For speech recognition tasks the models, 
% namely acoustic models and the language models, 
% are stored in persistent memory before using them.}
% 
% {\it Unsupervised learning}\/ can be thought of as finding patterns in the input data beyond what would be considered 
% pure unstructured noise\cite{ghahramani2004unsupervised}. Very often unsupervised learning is an application 
% of~statistical methods as in language modeling depicted in~Figure~\ref{fig:unsupervised}


\subsection{Speech parameterization}
\label{sub:param}
% \section{Signal processing}
% FIXME consult kaldi website with what I have written
% http://kaldi.sourceforge.net/feat.html
\ml{acoustic features}
Signal processing is an~important first step for speech recognition. However, we cover signal processing very briefly, 
because the methods described in this subsection are de facto standard and most of the toolkits use exactly the same 
algorithms. The~output of the~signal processing are acoustic feature vectors. 


The most used feature vectors are \ac{MFCC} coefficients and \ac{PLP} features. The toolkits used in our dialog system, 
Kaldi and \ac{HTK} toolkit, produce almost exactly the same \ac{MFCC} coefficients for given audio 
input.\footnote{The~subtle differences are caused by implementation approaches, but does not effect the quality 
    of~\ac{MFCC} coefficients in~significant way.}

An interested reader can find comprehensive introduction into signal processing 
in~the~fourth Chapter of Spoken Language Processing book\cite{huang2001spoken}.


Let us give a~specific example of signal processing steps: 
\small{\begin{enumerate}
    \item The raw audio signal is at first converted from continuous to discrete signal by {\it sampling}.  % TODO describe sampling https://en.wikipedia.org/wiki/Sampling_(signal_processing)
    \item The~discrete signal is transformed into {\it frequency domain}\/ by~\ac{DFT} in overlapping frames.
    \item The frequency spectrum obtained in previous step is transformed onto the \href{https://en.wikipedia.org/wiki/Mel_scale}{mel scale}, using triangular overlapping filters.
    \item From the mel frequencies the logs of the powers are taken from each of the mel frequencies.
    \item At the end the discrete cosine transform is applied on the list of mel log powers.
    \item The \ac{MFCC} coefficients are the amplitudes of the resulting spectrum.
\end{enumerate}
The {\it sampling frequency}\/ is typically 8000, 16000, 32000 or 44100 Hz and each of the samples is usually encoded in 8, 16 or 32 bits. In our experiments we use 16 kHz sampling frequency for 16 bit samples.  

The overlapping frames are used because \ac{DFT} is not accurate at the edges of frames. 
Windowing function like Hanning function applied on the signal removes the edge effect of~\ac{DFT}. 

\todo{obrazek}
For example,  the online Kaldi decoder uses $25ms$  frame length and the frames are shifted by $10ms$ for 16kHz sampling frequency. By multiplying the sample rate with frame length in seconds we find out that there are \todo{mezery} $16000 * 0.025 = 400$ samples in one frame. The frames are overlapping with $ 16000 * (0.025 - 0.01) = 240$ samples.

Kaldi uses by default 25 filters for 25 overlapping bins for~frequencies 
between 20 and \todo{divne formatovani} $Sampling frequency / 2 = 8000$, 
which is according the~Nyquist theorem\cite{jerri1977shannon} 
the~highest frequency that can be exactly determined in \ac{DFT}.

It is common to use only eight to twelve lowest-order \ac{MFCC} coefficients. In Kaldi we are using twelve of them. 
Note that the zero-order coefficients just measure the total frame energy and are often discarded.
} % \small

\ml{sampling}
To conclude, the signal processing samples the continuous audio at regular interval intervals. 
Fixed number of consecutive samples forms a window. The~windows are usually overlapping.
\ml{feature window}
The~acoustic features are computed for each of the overlapping window. 
% }}} Finished

% section signal_processing (end)

\subsection{Acoustic modeling}
\label{sub:am}
Let us return to the high level point of view to speech recognition from~Figure~\ref{fig:components}.
We described the signal processing unit and now we will focus on modeling the phonemes, the basic
units of speech. We will use the~statistical \ac{HMM} approach to phonemes modeling.

\begin{figure}[!htp]
    \begin{center}
    \input{images/supervised-general}
    \input{images/supervised-baum-welsh}
    \caption{Supervised learning idea and example}
    \label{fig:supervised} 
    \end{center}
\end{figure}

Acoustic models are trained using supervised learning. 

The~\ac{HMM} is a~very powerful statistical method of~characterizing the~observed data samples 
of~a~discrete-time series. Chapter 8, \cite{huang2001spoken}.
At first we will introduce {\it Markov Chain}, then \ac{HMM} will be defined. Later,  we will explain 
how are the acoustic and language models used in \ac{HMM} framework. 
In~the~Subsection~\ref{sub:dec_algorithm} we present the search algorithms for speech recognition.

\todo{acoustic modeling in Kaldi \url{http://kaldi.sourceforge.net/model.html}}

% \subsection*{Markov Chain}
% \label{ssub:markov_chain}
% \todo{Spoken Language Processing page 366}
% 
% \subsection{\acl{HMM}}
% \label{ssub:hmm}
% \todo{describe Hmm for phones}


\subsection{Language modeling}
\label{sub:lm}

Language models are trained using unsupervised training. 

\begin{figure}[!htp]
    \begin{center}
    % \input{images/unsupervised-general}
    \input{images/unsupervised-lm}
    \caption{Unsupervised learning idea and example}
    \label{fig:unsupervised} 
    \end{center}
\end{figure}

\subsection{Speech decoding}
\label{sub:decode}

\subsection{Evaluating \ac{ASR} quality}
\label{sub:eval}

\subsubsection*{The metrics in speech recognition}
\label{sub:the_metrics_in_speech_recognition}
In this thesis we are concerned about three aspects of speech decoder.
The speed, universality and quality of~\ac{ASR} hypothesis.

The universality of a decoder is not very well measurable and we will discuss it 
in~Chapter~\ref{cha:implementation} as an implementation property.

\ml{\acl{RTF}}
We will measure the speed of~the decoders by \acl{RTF} metric or we will express it by latency.
\todo{RTF malo srozumitelne}
\ac{RTF} is defined as $\ac{RTF} = \frac{P}{D}$, where $P$ is time of~the processing the audio by a~decoder on input with length $D$. 

\ml{latency}
The latency is a measure of delay. The delay is measured for each utterance in seconds. 
The delay is measured between time of submitting the last audio for given utterance to the decoder and 
the~time of returning the \ac{ASR} hypothesis from decoder.

\ml{\acl{WER}}
The quality of decoded hypothesis will be measured by \ac{WER}.
Note, that \ac{WER} is a minimum edit operation distance on words between two texts, the textual hypothesis
and its reference.
We will compute it by $\frac{S+D+I}{N}$, where $S$ is number of substitutions,
$D$ is number of deletions, $I$ number of insertions to the reference. 
The $N$ denotes the number of words in reference.

The other formats of textual hypothesis like n-best lists and lattice
will be converted to textual hypothesis, because the reference for our training data is only available  
in~form of text audio transcriptions.
From n-best list we take the best textual hypothesis directly as the first item. From lattice
we extract the transcriptions by search.  

% subsection the_metrics_in_speech_recognition (end)

\section{Kaldi}
\label{sec:back_kaldi}

\section{\ac{HTK}}
\label{sec:back_htk}
\todo{very brief}

\section{OpenJulius}
\label{sec:back_julius}
\todo{jake byly metody sumu ,  triphonem}


\subsection*{Decoding algorithm}
\label{sub:dec_algorithm}
The Viterbi algorithm is the~basic search algorithm for \ac{HMM}. 
Briefly
However

\todo{how online decoder works}

\subsubsection{Decoding with lattices}
\label{sub:lattice}
\todo{what are lattices, why is they are good, depth of lattices for dialog system,
problem of backward search for lattices}


% subsection lattice (end)

% subsection decoding_algorithm (end)


\section{Training acoustic models} 
\label{sec:train_ml}

This section describes the acoustic training in general and introduces the~maximum likelihood training methods.
The~maximum likelihood training is a base for discriminative methods for acoustic modeling, which are briefly
described in~Chapter~\ref{ref:training}.
In~Chapter~\ref{cha:training}, the focus is on comparing results obtained by numerous of training methods
and not on~explaining the methods.

\todo{Describe generative vs discriminative model}

\todo{clustering phones, trees, monophone and triphone training 
    \url{http://kaldi.sourceforge.net/tree_externals.html}
Shortly from Dans thesis extended Baum-Welsh}

% section training_acoustic_models (end)






% section general_introduction (end)

\section{Finite State Transducers} 
\label{sec:fst}
\todo{Introduction from:
 OPENFST explanation in Finite State Transducers mechanism in speech recognition -Dan Povey
 OPENFST article: OpenFst: A General and Efficient Weighted Finite-State Transducer Library Cyril Allauzen1 , Michael Riley2,3 , Johan Schalkwyk2 , Wojciech Skut2 , and Mehryar Mohri1
 SPEECH RECOGNITION WITH WEIGHTED FINITE-STATE TRANSDUCERS Mehryar Mohri}



\subsubsection*{\todo{Sources - cite them!}} % (fold)

\begin{itemize}
    \item \todo{Consult Vassil blogpost}
    \item \href{http://kaldi.sourceforge.net/graph.html} {Decoding graph construction in Kaldi}
    \item \href{http://kaldi.sourceforge.net/lattices.html} {Lattices in Kaldi}
\end{itemize}

\subsection{Decoding graph construction in~Kaldi} % (fold)
% FIXME add source http://kaldi.sourceforge.net/graph.html
% FIXME consult Vassil blogpost
Kaldi uses \ac{FST} as underlaying representation for all models, which are used to decoding. Consequently, 
training and decoding models in Kaldi can be expressed as sequence of operations above \acp{FST}.

Decoding is performed using a final result of training, so called {\it decoding graph}. 
From the high level point of view,
during training we are constructing the decoding graph 
\begin{equation} \label{eq:hclg}
HCLG = H\circ C\circ L\circ G
\end{equation}.

The symbol $\circ$ represents an associative binary operation of composition on \acp{FST}.
Namely, the transducers appearing in~Equation~\ref{eq:hclg} are:
\begin{enumerate}
    % source  http://kaldi.sourceforge.net/graph.html
    \item G is an acceptor that encodes the grammar or language model.
    \item L is the lexicon. Its input symbols are phones. Its output symbols are words.
    \item C represents the relationship between context-dependent phones on input and phones on output.
    \item H contains the \ac{HMM} definitions, that take as input id number of~\acp{PDF} and return context-dependent phones.
\end{enumerate}

Following one liner illustrates how Kaldi creates the decoding graph. 
\begin{equation}
   HCLG = asl(min(rds(det(H' o min(det(C o min(det(L o G)))))))) 
\end{equation}
Let us explain the shortcuts in the list below. Note that the operation are described in detail
at page \href{http://kaldi.sourceforge.net/fst_algo.html#fst_algo_stochastic} {Finite State Transducer algorithms in Kaldi}. 
% The source code of these operations is in fstext and corresponding command-line program are in fstbin/
\begin{itemize}
    \item asl - Add self loops to \ac{FST}
    \item rds - Remove disambiguation symbols from \ac{FST}
    \item H' is \ac{FST} H without self loops
    \item min -\ac{FST} minimization
    \item $A\circ B$  - Composition of \ac{FST} $A$ and $B$.
    \item det - Determinization of \ac{FST}
\end{itemize}

{\bf Kaldi stochasticity} - weights of outgoing arcs sum to 1.


\subsubsection*{Kaldi decoders} % (fold)
\begin{itemize}
    \item SimpleDecoder(Beam width) - straightforward implementation of Viterbi algorithm
    \item LatticeSimpleDecoder(Beam width d, Lattice delta $\delta$), where $ \delta \le d$

\end{itemize}
% subsection Kaldi Framework (end)

% section finite_state_automata (end)


% chapter background (end)
