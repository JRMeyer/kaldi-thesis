\chapter{Goals}
\label{cha:goals}
This chapters describes the goals of this thesis. 
In addition, in~Section~\ref{sec:why} we explain the objectives for integrating Kaldi framework into the dialog system Vystadial.\footnote{Vystadial is spoken dialogue system internally developed at UFAL MFF.} 

\section{Development of real time ASR decoder for the Kaldi toolkit}\footnote{The abbreviation ASR stands for automatic speech recognition.} 
\label{sec:development_of_real_time_asr_decoder_for_the_kaldi_toolkit}
Our main goal is is to develop a real time ASR decoder for the Kaldi toolkit. At first, we will identify what prevents the current KALDI decoders from being used as real time decoders. Namely, we will explore problems with latency and suggest potential speed improvements e.g. approximations, use of GPU, and so on. Based on the experiments we will suggest the optimal setting for the real time use of Kaldi decoder.

% section development_of_real_time_asr_decoder_for_the_kaldi_toolkit (end)

\section{Training Kaldi acoustic models} 
\label{sec:training_kaldi_acoustic_models}
Well trained models together with real time decoder recognize speech fast and with desired quality.

In the Vystadial project we have so far used HTK acoustic models with different decoders.
We want to develop training scripts for Kaldi framework which will produce acoustic models used with Kaldi decoders. The quality of the output for the Kaldi acoustic models and decoders should be better or comparable with~the~output of~acoustic models trained by HTK scripts and used against HDecode and OpenJulius decoders.

Using the Kaldi framework we will perform experiments which implement:
\begin{itemize}
    \item Standard generative training
    \item Learning linear transformations (e.g. HLDA\footnote{The abbreviation HLDA stands for heteroscedastic linear discriminant analysis})
    \item Discriminative training 
\end{itemize}

% section training_kaldi_acoustic_models (end)
 

\section{Comparison of used decoders and Kaldi decoders} 
\label{sec:compare_real_time_abilities_of_already_used_and_kaldi_decoders}
The main stress will be in comparing real time abilities and accuracy.
The speed of the decoders will be expressed in terms of real time factor.
The accuracy will be expressed in terms of word error rate (WER).

We will also compare and contrast possibilities of different output formats for each of tested decoders.
In addition we will take into account the memory consumption and stability of decoders.

There are HVite, HDecode, OpenJulius and Kaldi decoders to be evaluated.
% section compare_real_time_abilities_of_already_used_and_kaldi_decoders (end)

\section{Integrate Kaldi decoder into Vystadial framework} 
\label{sec:integrate_kaldi_decoder_into_vystadial_framework}
The Vystadial project is developed in Python language and consist of five major components.
The dialog system provides speech to speech interface. The components are linked into pipeline in order to process the spoken input and to generate speech.
Pipeline consist of:
\begin{enumarate}
    \item Voice Activity Detection (VAD)
    \item Automatic Speech Recognition (ASR) - Here we run one of our decoders.
    \item Semantic and Language Analysis (SLU)
    \item Dialog Manager (DM)
    \item Natural Language Generation (NLG)
\end{enumarate}

The integration task consist of building the Python interface for C++ Kaldi decoders and define the input and output interface for the ASR unit. We consider the VAD unit to be finished and we will not change it. Consequently, the input interface for ASR unit will be the same for all experiments. On the other hand, we need to create several interfaces and among ASR and SLU units according type of ASR output.

The reason for different ASR outputs is given by the needs of SLU unit. The SLU unit may work better with word lattices or confusion networks instead of classical textual ASR output. In this thesis we aim at providing different interfaces to SLU unit without any further experiments.

% 5) Implement RT decoder for KALDI (this will be C/C++), 
%   a) also implement integration with Python
%   b) perform optimisation of the code and the methods, 
%     especially make sure that you minimise the latency 
%     between the end of utterance and the returned results
%   c) use GPU for computing observation probabilities (GPU labeler), 
%     however, make sure that the GPU is not required
%   d) output of the decoder will be standard lattices 
%     (both phone and word)
%   e) compute posterior lattices (both phone and word),
%   f) provide confusion networks for these lattices
%   g) measure teh quality of the lattices, depth, oracle error rate    

% section integrate_kaldi_decoder_into_vystadial_framework (end)

    
\section{Why introducing a new decoder and toolkit for training acoustic models?} 
\label{sec:why}
In previous sections we introduced the goals of this thesis. In this section we argue why is the work necessary at all.


% section why_introducing_new_decoder_and_toolkit_for_training_acoustic_models_ (end)



So far, the Vystadial project is using the HTK toolkit to train acoustic models and the OpenJulius ASR for real time decoding.
% chapter goals (end)
