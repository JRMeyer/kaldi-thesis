\chapter{Goals}
\label{cha:goals}
This chapters describes the goals of this thesis. 
In addition, in~Section~\ref{sec:why} we explain the objectives for integrating Kaldi framework into the dialog system Vystadial.\footnote{Vystadial is spoken dialogue system internally developed at UFAL MFF.} 

\section{Development of real time ASR decoder for the Kaldi toolkit}\footnote{The abbreviation ASR stands for automatic speech recognition.} 
\label{sec:development_of_real_time_asr_decoder_for_the_kaldi_toolkit}
Our main goal is is to develop a real time ASR decoder for the Kaldi toolkit. At first, we will identify what prevents the current KALDI decoders from being used as real time decoders. Namely, we will explore problems with latency and suggest potential speed improvements e.g. approximations, use of GPU, and so on. Based on the experiments we will suggest the optimal setting for the real time use of Kaldi decoder.

% section development_of_real_time_asr_decoder_for_the_kaldi_toolkit (end)

\section{Training Kaldi acoustic models} 
\label{sec:training_kaldi_acoustic_models}
Well trained models together with real time decoder recognize speech fast and with desired quality.

In the Vystadial project we have so far used HTK acoustic models with different decoders.
We want to develop training scripts for Kaldi framework which will produce acoustic models used with Kaldi decoders. The quality of the output for the Kaldi acoustic models and decoders should be better or comparable with~the~output of~acoustic models trained by HTK scripts and used against HDecode and OpenJulius decoders.

Using the Kaldi framework we will perform experiments which implement:
\begin{itemize}
    \item Standard generative training
    \item Learning linear transformations (e.g. HLDA\footnote{The abbreviation HLDA stands for heteroscedastic linear discriminant analysis})
    \item Discriminative training 
\end{itemize}

% section training_kaldi_acoustic_models (end)
 

\section{Comparison of used decoders and Kaldi decoders} 
\label{sec:compare_real_time_abilities_of_already_used_and_kaldi_decoders}
The main stress will be in comparing real time abilities and accuracy.
The speed of the decoders will be expressed in terms of real time factor.
The accuracy will be expressed in terms of word error rate (WER).

We will also compare and contrast possibilities of different output formats for each of tested decoders.
In addition we will take into account the memory consumption and stability of decoders.

There are HVite, HDecode, OpenJulius and Kaldi decoders to be evaluated.
% section compare_real_time_abilities_of_already_used_and_kaldi_decoders (end)

\section{Integrate Kaldi decoder into Vystadial framework} 
\label{sec:integrate_kaldi_decoder_into_vystadial_framework}
The Vystadial project is developed in Python language and consist of five major components.
The dialog system provides speech to speech interface. The components are linked into pipeline in order to process the spoken input and to generate speech.
Pipeline consist of:
\begin{enumerate}
    \item Voice Activity Detection (VAD)
    \item Automatic Speech Recognition (ASR) - Here we run one of our decoders.
    \item Semantic and Language Analysis (SLU)
    \item Dialog Manager (DM)
    \item Natural Language Generation (NLG)
\end{enumerate}

The integration task consist of building the Python interface for C++ Kaldi decoders and define the input and output interface for the ASR unit. We consider the VAD unit to be finished and we will not change it. Consequently, the input interface for ASR unit will be the same for all experiments. On the other hand, we need to create several interfaces and among ASR and SLU units according type of ASR output.

The reason for different ASR outputs is given by the needs of SLU unit. The SLU unit may work better with word lattices or confusion networks instead of classical textual ASR output. In this thesis we aim at providing different interfaces to SLU unit without any further experiments.

% 5) Implement RT decoder for KALDI (this will be C/C++), 
%   a) also implement integration with Python
%   b) perform optimisation of the code and the methods, 
%     especially make sure that you minimise the latency 
%     between the end of utterance and the returned results
%   c) use GPU for computing observation probabilities (GPU labeler), 
%     however, make sure that the GPU is not required
%   d) output of the decoder will be standard lattices 
%     (both phone and word)
%   e) compute posterior lattices (both phone and word),
%   f) provide confusion networks for these lattices
%   g) measure teh quality of the lattices, depth, oracle error rate    

% section integrate_kaldi_decoder_into_vystadial_framework (end)

    
\section{Why introducing a new decoder and toolkit for training acoustic models?} 
\label{sec:why}
In previous sections we introduced the goals of this thesis. In this section we argue why is the work necessary at all.

So far, the Vystadial project is using the HTK toolkit to train acoustic models and the OpenJulius decoder for real time decoding.
Nevertheless, the set up used so far has several flaws.

One of the main goals of the Vystadial project is to release the code under Apache License, Version 2.0\footnote{\href{http://www.apache.org/licenses/LICENSE-2.0.html}{Link to Apache License 2.0}}. It is very important to us, because the licence is very permissive for the users. It does not limit the usage of the system only for educational purposes.

The HTK toolkit uses quite restrictive license. The license does not allow us to change the source code of its decoders (HDecode and HVite) and release the changed code under Apache license. We need to modify the source code of decoders. At least because of interfacing the decoder from Python and also because we need to implement specific input and output formats.

The OpenJulius is released under revised BSD style license, which is much better from our point of view. On the other hand, we have experienced software instability during decoding confusion networks using OpenJulius. In addition, OpenJulius seems to be hard to patched or otherwise improved due its coding style. Currently, it seems, that the stability problems around OpenJulius are not going to be resolved in near feature.

The Kaldi framework solves the drawbacks of HTK and OpenJulius. It is released under Apache License, Version 2.0. The same license we want to use. The Kaldi framework is cleanly written and has a nice developer community.
The decoders implemented in Kaldi already support lattices and confusion networks generation. 

% FIXME  add that Kaldi has rich training tools - for discriminative training

Currently, the Kaldi framework is used mostly for experimenting and it is not meant for real time used.
This thesis has put the goal of set up setting for real time decoding using Kaldi framework and create the Python interface for decoding. To conclude, the goals of this thesis fills missing functionality of Kaldi framework from Vystadial project perspective. 


% section why_introducing_new_decoder_and_toolkit_for_training_acoustic_models_ (end)


% chapter goals (end)
