% !TEX root = main.tex
\chapter{Conclusion}
\label{cha:conclusion}


The~Kaldi toolkit is a~speech recognition toolkit distributed under a~free license \cite{povey2011kaldi}.
The~toolkit is based on Finite State Transducers, implements state-of-the-art acoustic modelling techniques, is computationally efficient, and is already widely adapted among research groups.
Its only major drawback was the~lack of on-line recognition support.
Therefore, it could not be used directly in applications such as spoken dialogue systems.

This work presented the~\term{OnlineLatgenRecogniser}, an extension of the~Kaldi automatic speech recognition toolkit.
The~\term{OnlineLatgenRecogniser} is distributed under the~Apache 2.0 license, and therefore it is freely available for both research and commercial applications.
The~recogniser and its Python extension is stable and intensively used in a~publicly available spoken dialogue system \cite{ptics2014url}.
Thanks to the~use of a~standard Kaldi lattice decoder, the~recogniser produces high quality word posterior lattices.
% In addition, this enable the~recogniser to benefit from future improvements in the~Kaldi decoders.


The training scripts as well as the source code of the \term{OnlineLatgenRecogniser} are currently merged into Kaldi repository\footnote{\url{http://sourceforge.net/p/kaldi/code/HEAD/tree/sandbox/oplatek2/src/dec-wrap/}}\footnote{\url{http://sourceforge.net/p/kaldi/code/HEAD/tree/sandbox/oplatek2/egs/vystadial/}}.
The Alex dialogue system and the integration of \term{OnlineLatgenRecogniser} is Apache, 2.0 licensed and freely available on Github\footnote{\url{https://github.com/UFAL-DSG/alex}}.
The training scripts, the \term{OnlineLatgenRecogniser} and its Python wrapper \term{PyOnlineLatgenRecogniser} were developed also under Apache, 2.0 license on Github\footnote{\url{https://github.com/UFAL-DSG/pykaldi}, \url{https://github.com/UFAL-DSG/pyfst}} 

% The~\term{OnlineLatgenRecogniser} recogniser, an extension the~Kaldi framework, is freely available\footnote{Apache, 2.0 license} and significantly improved speech recognition for a~dialog system Alex.
% The~recognizer and its Python wrapper is stable and intensively used in a~freely available dialogue system in Czech public transport domain.
% The~speech decoder is able to output high quality lattices, which can be utilised in SLU unit of dialogue system. 
% The~scripts, Czech and English data  used for acoustic training are also freely available online.
% 
% The~\term{OnlLatticeFasterDecoder} modular design allows reusing the~code of \term{LatticeFasterDecoder}, which resulted in improving the~decoder based changes from \term{LatticeFasterDecoder}.
% The~training scripts and also the~speech recognizer code is in process of integration back to Kaldi toolkit.
% 
% \subsection*{Future work}
% Firstly, we se the~future work in implementing more sophisticated feature transformation and speech parameterisation interface, so decoding with larger variety of feature transformations can be supported.
% Secondly, the~recordings with extreme latency values can be detected using the~one-best hypothesis.
% Consequently, the~backward decoding could be skipped for recordings which contains only noise.
% Finally, the~word posterior lattices should be more tightly integrated with SLU unit,
% and the~potential of oracle WER should be more utilised.
% 

The work specified by goals in introduction varies in many aspects. 
We successfully trained acoustic models, design and also implement decoders interface, improve real-time decoder and prepared experiments for evaluating results.

In addition to our implementation effort, we have also co-authored an article which uses \ac{AM} training scripts described in Chapter~\ref{cha:train}.
The article\cite{korvas_2014} describes the Czech and English Vystadial data sets as well as its acoustic modelling scripts in Kaldi and \ac{HTK}.
We also submitted an article about \term{OnlineLatgenRecogniser's} implementation and properties to the Sigdial conference\footnote{\url{http://www.sigdial.org/}}. The article is currently in a~review process.

Future plans include implementing more sophisticated speech parameterisation interface and feature transformations, implementing normalisation of word posterior lattices and exploring acoustic modelling based on \acl{DNN}.
% We would like to focus on acoustic modelling with \acl{DNN}.
% The \ac{DNN} provide more accurate acoustic probabilities, which should lead to faster beam search, because the search is more informed.\cite{zhang2014improving} 
% We see the challenge in implementation of \acl{DNN} evaluation in real time, probably using \ac{GPU}.

\section*{Acknowledgments}
This research was partly funded by the~MEYS of the~Czech Republic under the~grant agreement LK11221 and core research funding of Charles University in Prague.
The work described herein uses language resources hosted by the LINDAT/CLARIN repository, funded by the project LM2010013 of the MEYS of the Czech Republic.
We would also like to thank Daniel Povey, Vassil Panayotov, Pavel Mencl, Ondřej Dušek, Matěj Korvas, Lukáš Žilka, David Marek and Tomáš Martinec for their useful comments and discussions.
