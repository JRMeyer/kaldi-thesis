% !TEX root = main.tex
\chapter{Introduction}
\label{cha:intro}

A~spoken dialogue is the~most intuitive way of~communication among people. 
% Nowadays, the~spoken dialogue is becoming popular choice of~communication even for human-device interaction. 
The~quality of~a~dialogue largely depends on the~quality of~speech recognition because the~reasoning and the~answer is based on the~recognised speech. 

In this work, we build \acl{ASR} for a~dialogue system called Alex. 
We see the~added value of this thesis in:
\begin{itemize}
    \item a~new training scripts deployed with open acoustic data\cite{korvas_2014}, 
    \item but also in new C++ interface for speech recognition 
    \item and its Python wrapper which is integrated into Alex dialogue system. 
\end{itemize}
Training scripts, which use free publicly available data, evaluate the~quality of trained \aclp{AM}.
We use Kaldi speech recognition toolkit\cite{povey2011kaldi} for acoustic modeling as well as for real-time recognition the~textual representation from speech.
The~newly developed speech recogniser is deployed in the~dialogue system Alex available at a~public toll-free line 800 899 998. 

% The~Alex dialogue system is mostly domain and language independent.
% Currently, we are testing the~dialogue system on a~public Czech phone call service
% \footnote{The~phone line +420 800 899 998 is for free for Czech callers.}.
% A~caller can ask about weather and public transport information in the~Czech republic.

\section{The~problem} 
\label{sec:problem}

The~\ac{ASR} in a~dialogue system closely interacts with a~\acl{SLU} unit.
The~\ac{SLU} unit typically classifies the~speech better if the~speech recogniser outputs more than one hypothesis for one utterance. 
A~word lattice effectively represents multiple hypothesis, so it is convenient for passing the~hypothesis between \ac{ASR} and \ac{SLU} unit.

The~Alex dialogue system has used the~\ac{HTK} toolkit\cite{young94htk} and OpenJulius\cite{lee2009julius} lattice speech recogniser in order to train acoustic models respectively to decode lattices in real time. 
Unfortunately, our project members were experiencing crashes of OpenJulius during extracting lattices.

We were looking for another open source toolkit with a~real-time speech recogniser because OpenJulius has a~complicated source code and relatively slow development of both \ac{HTK} and OpenJulius

We chose the~Kaldi toolkit because its speech recognisers can produce high-quality lattices.\cite{povey2012generating}
In addition, the~Kaldi toolkit deploys modern training recipes, is actively maintained and is distributed under the~permissive Apache 2.0 license\footnote{\url{http://www.apache.org/licenses/LICENSE-2.0}}.
On the~other hand, the~speech recognisers in Kaldi do not support interface convenient for a~dialogue system which can process audio stream incrementally.

We developed the~on-line interface suitable for a~real-time use of a~lattice recogniser, and we rewrote its feature preprocessing functionality to fit our interface.
So far, the~Kaldi developers focused on improving acoustic model training. 
In August 2012\footnote{The~changes were introduced by \href{https://sourceforge.net/p/kaldi/code/1259/}{svn commit 1259}.} Kaldi team published a~demo version of~an on-line one best hypothesis speech recogniser.

\section{The~goals of~the~thesis} 
\label{sec:goals}
The~goals of the~thesis are presented in order as will be implemented:
\begin{enumerate}
    \item \acp{AM} will be trained to evaluate the~new recogniser.
    \item The~new recogniser will be developed so its Python wrapper can be deployed into our dialogue system Alex.
    \item Finally, we will integrate the~recogniser into our Alex \ac{SDS} written in Python and evaluate its performance.
\end{enumerate}

\subsection{Training acoustic models} 
\label{sub:training_kaldi_acoustic_models}
A~\acl{ASR} recogniser requires two pre trained components, an~\acl{AM} and a~\acl{LM}. 
We focus on finding the~best \acl{AM} for the~Kaldi toolkit. 
The~\acl{LM} is changed dependently on targeted domain.

We aim at developing acoustic model training scripts using the~Kaldi toolkit with such quality, that resulting \acp{AM} could be compared with the~\acp{AM} trained with previously used \ac{HTK} toolkit. 
The~scripts will be developed for Czech and English transcribed acoustic data.

\subsection{Development real-time speech recogniser} 
\label{sub:compare_rt}

We should modify Kaldi speech recogniser in order to allow incremental speech recognition.
The~resulting incremental interface should be as simple as possible yet allow state-of-the-art performance.
In addition, we will implement such speech parametrisation and feature transformation preprocessing, so high-quality acoustic models can be used.
Finally, we should compute the~posterior probabilities of the~word lattice representing multiple \ac{ASR} hypotheses.

% The~process of incremental speech recognition is represented by a~single instance of \term{OnlineLatgenRecogniser} class, which provides simple interface to speech recognition.

In addition, we may suggest potential speed improvements e.g.\ approximations, use of \ac{GPU} or \ac{DNN} for speech processing\cite{vesely2013sequencediscriminative}.

\subsection[Integration into Alex \acs{SDS} framework]{Integration into Alex \acl{SDS} framework} 
\label{sub:integration}
We should develop a~thin wrapper which efficiently exposes the~speech recognition interfaces into Python.
We make sure that the~lattices which are the~output of the~Kaldi recogniser can be also accessed from Python.
The~resulting recogniser should be integrated into Alex \ac{SDS} and the~decoding parameters are should be tuned to obtain best performance.
The~evaluation of speech recognition setup is important part of the~integration.

\section*{Thesis outline} 
In~Chapter~\ref{cha:background} we introduce a~fundamental theory of speech recognition for related areas to our work.
In Sections~\ref{sec:back_htk} and~\ref{sec:back_julius} we describe alternatives to Kaldi speech recognition toolkit. 
At the~end of the~chapter, we present OpenFST framework which allows the~Kaldi library effectively implement many standard speech recognition operations. 
To obtain high-quality \aclp{AM}, we develop training scripts for Czech and English data described in~Chapter~\ref{cha:train}. 
In addition, we compare acoustic models trained by Kaldi and previously used~\ac{HTK} toolkit. 
Chapter~\ref{cha:decoder} presents in detail the~new Kaldi real-time recogniser and discuss its on-line properties.
We distinguish the~original work done by the~Kaldi team and our improvements. 
Then in Chapter~\ref{cha:integration}, we describe deployment of the~real-time recogniser into dialogue system Alex, we suggest evaluation criteria and also evaluate the~integrated recogniser accordingly.
Finally, Chapter~\ref{cha:conclusion} summarises the~thesis and concludes with future research directions.
