% !TEX root = main.tex
\chapter{Introduction}
\label{cha:intro}

A spoken dialog is the most intuitive way of~communication among people. 
% Nowadays, the spoken dialog is becoming popular choice of~communication even for human-device interaction. 
The quality of~a~dialog largely depends on the quality of~speech recognition because the~reasoning and the~answer is based on the recognised speech. 

In this work, we build \acl{ASR} for a dialog system called Alex. 
We use Kaldi speech recognition toolkit\cite{povey2011kaldi} for acoustic modeling as well as real-time recognition the textual representation from speech.
We see the added value of this thesis in a~new training scripts deployed with open acoustic data\cite{korvas_2014}, but also in new C++ interface for speech recognition and its Python wrapper which were integrated into Alex dialogue system. 
Training scripts, which use free publicly available data, evaluate the quality of trained \aclp{AM}.
The~newly developed speech recogniser is deployed in the dialogue system Alex available at a public toll-free line 800 899 998. 

% The Alex dialog system is mostly domain and language independent.
% Currently, we are testing the dialog system on a~public Czech phone call service
% \footnote{The phone line +420 800 899 998 is for free for Czech callers.}.
% A caller can ask about weather and public transport information in the~Czech republic.

\section{The problem} 
\label{sec:problem}

The speech recognition in a dialog system closely interacts with a~\acl{SLU} unit.
The \ac{SLU} unit typically classifies the speech better if the speech recogniser outputs more than one hypothesis for one utterance. 
A word lattice effectively represents multiple hypothesis, so it is convenient for passing the hypothesis between \ac{ASR} and \ac{SLU} unit.

The Alex dialog system has been using the \ac{HTK} toolkit\cite{young94htk} and OpenJulius\cite{lee2009julius} lattice decoder in order to train acoustic models respectively to decode lattices in real time. 
Unfortunately, our project members were experiencing crashes of OpenJulius during extracting lattices.

Bearing in mind the OpenJulius's complicated code base and relatively slow development of both \ac{HTK} and OpenJulius, we were looking for another open source toolkit with a real-time decoder.

We chose the~Kaldi toolkit because the Kaldi toolkit deploys modern training recipes, and is actively maintained. 
Moreover, Kaldi is distributed under the~permissive Apache 2.0 license\footnote{\url{http://www.apache.org/licenses/LICENSE-2.0}}.
On the other hand, the Kaldi toolkit had no lattice decoder with interface convenient for a dialog system which can process audio stream incrementally.

The Kaldi community focused on improving acoustic model training. 
In August 2012\footnote{The changes were introduced by \href{https://sourceforge.net/p/kaldi/code/1259/}{svn commit 1259}.} Kaldi team published a~demo version of~an on-line one best hypothesis decoder.
The on-line decoder inspired us in designing the on-line interface suitable for real-time use of a lattice decoder, and we rewrote its feature preprocessing functionality to fit our interface.

\section{The goals of~the~thesis} 
\label{sec:goals}
The goals of the thesis are presented in order as were implemented:
\begin{enumerate}
    \item \acp{AM} are trained to evaluate the new recogniser.
    \item The new recogniser is developed so its Python wrapper can be deployed into our dialogue system Alex.
    \item Finally, we integrate the recogniser into our Alex \ac{SDS} written in Python and evaluate its performance.
\end{enumerate}

\subsection{Training acoustic models} 
\label{sub:training_kaldi_acoustic_models}
A \acl{CSR} decoder requires two pre trained components, an~\acl{AM} and a~\acl{LM}. 
We focus on finding the best \acl{AM} for the~Kaldi toolkit. 
The \acl{LM} is changed dependently on targeted domain.

We aim at developing acoustic model training scripts using the~Kaldi toolkit with such quality, that resulting \acp{AM} could be compared with the~\acp{AM} trained with previously used \ac{HTK} toolkit. 
The scripts are developed for Czech and English transcribed acoustic data.


\subsection{Development real-time speech recogniser} 
\label{sub:compare_rt}

We modify Kaldi \term{LatticeFasterDecoder} in order to allow incremental speech recognition.
The resulting incremental interface should be as simple as possible yet allow state-of-the art performance.
In addition, we implement such speech parametrisation and feature transformations preprocessing, that high-quality acoustic models can be used.
Finally, we compute the posterior probabilities of the~word lattice representing multiple \ac{ASR} hypotheses.

The process of incremental speech recognition is represented by a single instance of \term{OnlineLatgenRecogniser} class,
which provides simple interface to speech recognition.

In addition, we suggest potential speed improvements e.g.\ approximations, use of \ac{GPU} 
or \ac{DNN} for speech processing\cite{vesely2013sequencediscriminative}.

\subsection[Integration into Alex \acs{SDS} framework]{Integration into Alex \acl{SDS} framework} 
\label{sub:integration}
The \term{PyOnlineLatgenRecogniser} is a thin wrapper which efficiently exposes the speech recognition interfaces \term{OnlineLatgenRecogniser} into Python.
In addition, we make sure that the lattices which are the output of \term{OnlineLatgenRecogniser} can be also accessed from Python.
The \term{PyOnlineLatgenRecogniser} is integrated into Alex \ac{SDS} and the decoding parameters are tuned to obtain best performance.
The evaluation of speech recognition setup is important part of the integration.

\section*{Thesis outline} 
In~Chapter~\ref{cha:background} we introduce a fundamental theory of speech recognition for related areas to our work.
In Sections~\ref{sec:back_htk} and~\ref{sec:back_julius} we describe alternatives to Kaldi speech recognition toolkit. 
At the end of the chapter, we present OpenFST framework which allows the Kaldi library effectively implement many standard speech recognition operations. 
To obtain high-quality \aclp{AM}, we develop training scripts for Czech and English data described in~Chapter~\ref{sef:train}. 
In addition, we compare acoustic models trained by Kaldi and previously used~\ac{HTK} toolkit. 
Chapter~\ref{cha:decoder} presents in detail the new Kaldi real-time recogniser and discuss its on-line properties.
We distinguish the original work done by the~Kaldi team and our improvements. 
Then in Chapter~\ref{cha:integration}, we describe deployment of the real-time recogniser into dialogue system Alex, we suggest evaluation criteria and also evaluate the integrated recogniser accordingly.
Finally, Chapter~\ref{cha:conclusion} summarises the thesis and concludes with future research directions.
